{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd234d47",
   "metadata": {},
   "source": [
    "# CH08_4_Generating and Training Convolution Neural Network\n",
    "\n",
    "- Last update : 2022.04.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfa2a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b65c9",
   "metadata": {},
   "source": [
    "## # Generating Forward propagation calculation of Convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "364127a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Implementing Convolution \n",
    "\n",
    "def forpass(self, x): \n",
    "    # Implementing 3 X 3 Convolution \n",
    "    c_out1 = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84647db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Implementing ReLU function \n",
    "\n",
    "def forpass(self, x): \n",
    "    ...\n",
    "    # applying ReLU function \n",
    "    r_out = tf.nn.relu(c_out)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Applying pooling and modifying fully connected layers \n",
    "\n",
    "def forpass(self, x): \n",
    "    ...\n",
    "    # applying 2 X 2 max pooling\n",
    "    p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\n",
    "    # spreading out output except initial batch dimension \n",
    "    f_out = tf.reshape(p_out, [x.shape[0], -1])\n",
    "    z1 = tf.matmul(f_out, self.w1) + self.b1   # Calculating regression function of first layer\n",
    "    a1 = tf.nn.relu(z1)                        # applying activation function \n",
    "    z2 = tf.matmul(a1, self.w2) +self.b2       # Calculating regression function of second layer   \n",
    "    return z2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfa687",
   "metadata": {},
   "source": [
    "## # Generating Backword propagation calculation of Convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "454aa6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 5. 14. 29.], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Auto defferentiation usage \n",
    "\n",
    "x = tf.Variable(np.array([1.0, 2.0, 3.0]))\n",
    "\n",
    "with tf.GradientTape( ) as tape:\n",
    "    y = x**3 + 2*x + 5\n",
    "    \n",
    "# Calculating Gradient \n",
    "print (tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a0652f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Implementing backward propagation calculation \n",
    "\n",
    "def training(self, x, y): \n",
    "    m = len(x)                        # saving the no. of samples \n",
    "    with tf.GradientTape() as tape:\n",
    "        z = self.forpass(x)           # Implementing forward propagation calculation \n",
    "        # calculating loss \n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "    ...        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe1fb922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.99908031e-17 5.43406367e-17 1.47713165e-16], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(np.array([1.0, 2.0, 3.0]))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.nn.softmax(x)\n",
    "    \n",
    "# calculating gradient \n",
    "print (tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fa292860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculating Gradient \n",
    "\n",
    "def training(self, x, y): \n",
    "    ...\n",
    "    weights_list = [self.conv_w, self.conv_b, self.w1, self.b1, self.w2, self.b2]\n",
    "    # Calculating gradient on the weight \n",
    "    grads = tape.gradient(loss, weights_list)\n",
    "    # updating weights\n",
    "    self.optimizer.apply_gradients(zip(grads, weights_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec77e6",
   "metadata": {},
   "source": [
    "## # Initializing weight by making optimizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "56633010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Modifying fit() method\n",
    "\n",
    "def fit(self, x, y, epochs=100, x_val=None, y_val=None): \n",
    "    self.init_weights(x.shape, y.shape[1])      # initializing weights of hidden layers and output layers \n",
    "    self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\n",
    "    # repeats the routine epoch times \n",
    "    for i in range(epochs): \n",
    "        print (\"Epoch\", i, end=' ')\n",
    "        # circulating mini batch returned from generator function \n",
    "        batch_losses = []\n",
    "        for x_batch, y_batch in self.gen_batch(x, y): \n",
    "            print ('.', end='')\n",
    "            self.training(x_batch, y_batch)\n",
    "            # recording batch losses\n",
    "            batch_losses.append(self.get_loss(x_batch, y_batch))\n",
    "        print ()\n",
    "        # calculating avearage batch loss and saving it to loss\n",
    "        self.losses.append(np.mean(batch_losses))\n",
    "        # calculating losses on the verifying set \n",
    "        self.val_losses.append(self.get_loss(x_val, y_val))                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c737f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Modifying init_weights() method\n",
    "def init_weights(self, input_shape, n_classes): \n",
    "    g = tf.initializers.glorot_uniform()\n",
    "    self.conv_w = tf.Variables(g((3, 3, 1, self.n_kernels)))\n",
    "    self.conf_b = tf.Variables(np.zeros(self.n_kernels), dtype=float)\n",
    "    n_features = 14 * 14 * self.n_kernels\n",
    "    self.w1 = tf.Variables(g((n_features, self.units)))    # (No. of features, hidden layer size)\n",
    "    self.b1 = tf.Variables(np.zeros(self.units), dtype = float)   # size of hidden layer\n",
    "    self.w2 = tf.Variables(g((self.units, n_classes)))     # (size of hidden layer, no. of classes)\n",
    "    self.b2 = tf.Variables(np.zeros(n_classes), dtype = float)  # no. of classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e744ab0",
   "metadata": {},
   "source": [
    "## # What is glorot_uniform( )?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a67c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of weight by glorot initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30f291d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNetwork: \n",
    "    \n",
    "    def __init__(self, n_kernels=10, units=10, batch_size=32, learning_rate=0.1):\n",
    "        self.n_kernels = n_kernels         # No. of Kernel of Convolution \n",
    "        self.kernel_size = 3               # size of Kernel \n",
    "        self.optimizer = None              # Optimizer  \n",
    "        self.conv_w = None                 # weight of convolution layer  \n",
    "        self.conv_b = None                 # intersect of convolution layer  \n",
    "        self.units = units                 # No. of neuron in hidden layer \n",
    "        self.batch_size = batch_size       # batch size \n",
    "        self.w1 = None                     # weight of hidden layer  \n",
    "        self.b1 = None                     # interscept of hidden layer  \n",
    "        self.w2 = None                     # weight of output layer  \n",
    "        self.b2 = None                     # interscect of output layer  \n",
    "        self.a1 = None                     # activation output of hidden layer  \n",
    "        self.losses = []                   # Tainning loss  \n",
    "        self.val_losses = []               # verifying loass \n",
    "        self.lr = learning_rate            # learning rate \n",
    "    \n",
    "    def forpass(self, x):\n",
    "        # Implementing 3 x 3 convulution \n",
    "        c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\n",
    "        # Implementing ReLU activation function \n",
    "        r_out = tf.nn.relu(c_out)\n",
    "        # Implementing 2X2 max pooling \n",
    "        p_out = tf.nn.max_pool2d(r_out, ksize = 2, strides=2, padding='VALID')\n",
    "        # Spreading out output except first batch dimension \n",
    "        f_out = tf.reshape(p_out, [x.shape[0], -1])\n",
    "        z1 = tf.matmul(f_out, self.w1) + self.b1       # calculating regression function of first layer \n",
    "        a1 = tf.nn.relu(z1)                            # applying activation function \n",
    "        z2 = tf.matmul(a1, self.w2) + self.b2          # calculating regression function of second layer \n",
    "        return z2 \n",
    "                \n",
    "    def init_weights(self, input_shape, n_classes):\n",
    "        g = tf.initializers.glorot_uniform()\n",
    "        self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\n",
    "        self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\n",
    "        n_features = 14 * 14 * self.n_kernels\n",
    "        self.w1 = tf.Variable(g((n_features, self.units)))            # (no. of features, size of hidden layer)\n",
    "        self.b1 = tf.Variable(np.zeros(self.units), dtype = float)    # size of hidden layers \n",
    "        self.w2 = tf.Variable(g((self.units, n_classes)))             # (no. of hidden layers, no. of classes)\n",
    "        self.b2 = tf.Variable(np.zeros(n_classes), dtype = float)    # no. of classes \n",
    "        \n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
    "        self.init_weights(x.shape, y.shape[1])         # initializing weights of hidden layer and output layer\n",
    "        self.optimizer = tf.optimizers.SGD(learning_rate = self.lr)\n",
    "        # repeate the routine epoch times \n",
    "        for i in range(epochs): \n",
    "            print('Epoch', i , end =' ')\n",
    "            # circulating mini batch returned from generator function \n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in self.gen_batch(x, y): \n",
    "                print ('.', end='')\n",
    "                self.training(x_batch, y_batch)\n",
    "                # recording batch loss \n",
    "                batch_losses.append(self.get_loss(x_batch, y_batch))\n",
    "            print()\n",
    "            # calculating batch loss average and saving it to training loss \n",
    "            self.losses.append(np.mean(batch_losses))\n",
    "            # calculating loss on the verifying set \n",
    "            self.val_losses.append(self.get_loss(x_val, y_val))\n",
    "            \n",
    "    # mini-batch generator function         \n",
    "    def gen_batch(self, x, y):          \n",
    "        bins = len(x) // self.batch_size                      # frequency of mini-batch  \n",
    "        indexes = np.random.permutation(np.arange(len(x)))   # shuffle the indexes \n",
    "        x = x[indexes]\n",
    "        y = y[indexes]\n",
    "        for i in range(bins): \n",
    "            start = self.batch_size * i \n",
    "            end = self.batch_size * (i + 1)\n",
    "            yield x[start:end], y[start:end]    # returning the value after slicing it in batch_size\n",
    "        \n",
    "    def training(self, x, y): \n",
    "        m = len(x)\n",
    "        with tf.GradientTape() as tape:\n",
    "            z = self.forpass(x)                 # implementing forward propagation calculation \n",
    "            # calculating the loss \n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "        weights_list = [self.conv_w, self.conv_b, self.w1, self.b1, self.w2, self.b2]\n",
    "        \n",
    "        # Calculating gradient on the weights \n",
    "        grads = tape.gradient(loss, weights_list)\n",
    "        # updating weights\n",
    "        self.optimizer.apply_gradients(zip(grads, weights_list))        \n",
    "        \n",
    "    def predict(self, x): \n",
    "        z = self.forpass(x)                      # Implementing forward propagation calculation \n",
    "        return np.argmax(z.numpy(), axis=1)\n",
    "            \n",
    "    def score(self, x, y): \n",
    "        # returning True ratio after comparing prediction to target row vector\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
    "                \n",
    "    def get_loss(self, x, y): \n",
    "        z = self.forpass(x)                      # Implementing forward propagation calculation \n",
    "        # saving loss after calculation \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, z))\n",
    "        return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933f8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97043b1a",
   "metadata": {},
   "source": [
    "## # Training Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a4128edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading Dataset\n",
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ce7bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Spliting Training Dataset into training set and verifying set\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, \n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94175c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transforming target into one-hot incoding\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a7b3148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Preparing input data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_val = x_val.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02df7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Standardization Preprocessing for Input data \n",
    "x_train = x_train / 255\n",
    "x_val = x_val /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "508150ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 1 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 2 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 3 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 4 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 5 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 6 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 7 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 8 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 9 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 10 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 11 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 12 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 13 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 14 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 15 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 16 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 17 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 18 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 19 .......................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "# 6. Training Model\n",
    "\n",
    "cn = ConvolutionNetwork(n_kernels=10, units=100, batch_size= 128, learning_rate=0.01)\n",
    "cn.fit(x_train, y_train_encoded, x_val=x_val, y_val=y_val_encoded, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40aa51a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Plotting Training loss and verifying loss and Checking out accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cn.losses)\n",
    "plt.plot(cn.val_losses)\n",
    "plt.ylabel('loss', fontsize=\"16\")\n",
    "plt.xlabel('iteration', fontsize=\"16\")\n",
    "plt.title('Loss function', fontsize=\"22\")\n",
    "\n",
    "plt.legend(['train_loss', 'val_loss'], fontsize=\"16\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2c37f84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8791666666666667"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.score(x_val, y_val_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_py37",
   "language": "python",
   "name": "tf_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
